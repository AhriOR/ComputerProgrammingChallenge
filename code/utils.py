import pandas as pd
import os
from PIL import Image
import torch
from torch.utils.data import Dataset, DataLoader, random_split  # å¯¼å…¥random_splitç”¨äºåˆ’åˆ†
from torchvision import transforms
from sklearn.preprocessing import LabelEncoder

# å…¨å±€å­—å…¸ï¼šå­˜å‚¨ç±»åˆ«æ˜ å°„ï¼ˆåŸå§‹ID -> ä¸­æ–‡åç§°ï¼‰
image_category_dict = {}


class PlantImageDataset(Dataset):
    def __init__(self, csv_file, image_dir, transform=None):
        """
        æ¤ç‰©å›¾åƒæ•°æ®é›†ï¼ˆä¼˜åŒ–ç‰ˆï¼‰ï¼šè‡ªåŠ¨è¿‡æ»¤æ— æ•ˆå›¾ç‰‡ï¼Œç¡®ä¿æ•°æ®åŠ è½½ç¨³å®š
        Args:
            csv_file: CSVæ–‡ä»¶è·¯å¾„ï¼ˆåŒ…å«filenameã€category_idç­‰å­—æ®µï¼‰
            image_dir: å›¾åƒå­˜æ”¾ç›®å½•
            transform: å›¾åƒé¢„å¤„ç†ç®¡é“
        """
        self.image_dir = image_dir
        self.transform = transform

        # 1. è¯»å–CSVæ–‡ä»¶ï¼ˆæ”¯æŒå¤šç§ç¼–ç ï¼‰
        try:
            self.data_frame = pd.read_csv(csv_file, encoding='utf-8')
        except UnicodeDecodeError:
            try:
                self.data_frame = pd.read_csv(csv_file, encoding='gbk')
            except:
                self.data_frame = pd.read_csv(csv_file, encoding='latin-1')

        # 2. è¿‡æ»¤æ— æ•ˆå›¾ç‰‡è·¯å¾„ï¼ˆæ ¸å¿ƒä¼˜åŒ–ï¼šæå‰æ’é™¤ä¸å­˜åœ¨çš„å›¾ç‰‡ï¼‰
        valid_rows = []
        invalid_count = 0  # ç»Ÿè®¡æ— æ•ˆæ ·æœ¬æ•°é‡
        for idx, row in self.data_frame.iterrows():
            img_path = os.path.join(self.image_dir, row['filename'])
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”éç©ºï¼ˆé¿å…0å­—èŠ‚çš„æŸåæ–‡ä»¶ï¼‰
            if os.path.exists(img_path) and os.path.getsize(img_path) > 0:
                valid_rows.append(row)
            else:
                invalid_count += 1
                # æ‰“å°æ— æ•ˆæ ·æœ¬ä¿¡æ¯ï¼ˆæ–¹ä¾¿åç»­æ ¸å¯¹ï¼‰
                if invalid_count <= 10:  # åªæ‰“å°å‰10ä¸ªæ— æ•ˆæ ·æœ¬ï¼Œé¿å…æ—¥å¿—å†—ä½™
                    print(f"âš ï¸ è¿‡æ»¤æ— æ•ˆå›¾ç‰‡ï¼ˆä¸å­˜åœ¨æˆ–ä¸ºç©ºï¼‰ï¼š{img_path}")

        # æ›´æ–°æ•°æ®æ¡†ä¸ºä»…åŒ…å«æœ‰æ•ˆæ ·æœ¬
        self.data_frame = pd.DataFrame(valid_rows)
        print(
            f"\næ•°æ®è¿‡æ»¤å®Œæˆï¼šåŸå§‹æ ·æœ¬æ•° {len(valid_rows) + invalid_count}ï¼Œæœ‰æ•ˆæ ·æœ¬æ•° {len(self.data_frame)}ï¼Œè¿‡æ»¤æ— æ•ˆæ ·æœ¬ {invalid_count}")

        # 3. æ ‡ç­¾ç¼–ç ï¼ˆåŸºäºè¿‡æ»¤åçš„æœ‰æ•ˆæ ·æœ¬ï¼Œå…¨å±€ç»Ÿä¸€ç¼–ç ï¼Œåˆ’åˆ†åå­é›†å…±ç”¨ï¼‰
        self.label_encoder = LabelEncoder()
        self.data_frame['encoded_label'] = self.label_encoder.fit_transform(self.data_frame['category_id'])

        # 4. æ‰“å°æ•°æ®é›†åŸºæœ¬ä¿¡æ¯
        print(f"æœ‰æ•ˆæ•°æ®é›†æ€»å¤§å°: {len(self.data_frame)}")
        print(f"ç±»åˆ«æ•°é‡: {self.data_frame['encoded_label'].nunique()}")
        print(f"æ ‡ç­¾èŒƒå›´: {self.data_frame['encoded_label'].min()} - {self.data_frame['encoded_label'].max()}")
        print(f"ç±»åˆ«åˆ†å¸ƒï¼ˆå‰5ç±»ï¼‰:\n{self.data_frame['encoded_label'].value_counts().head()}")

        # 5. æ‰“å°ç±»åˆ«æ˜ å°„ç¤ºä¾‹
        print("\nç±»åˆ«æ˜ å°„ç¤ºä¾‹:")
        sample_mapping = self.data_frame[['category_id', 'encoded_label', 'chinese_name']].drop_duplicates().head(10)
        for _, row in sample_mapping.iterrows():
            print(f"  åŸå§‹ID: {row['category_id']} -> ç¼–ç å: {row['encoded_label']}ï¼ˆ{row['chinese_name']}ï¼‰")
            # æ›´æ–°å…¨å±€ç±»åˆ«æ˜ å°„å­—å…¸
            image_category_dict[str(row['category_id'])] = row['chinese_name']

    def __len__(self):
        return len(self.data_frame)

    def __getitem__(self, idx):
        # è·å–æ ·æœ¬ä¿¡æ¯ï¼ˆidxä¸ºæ•°æ®é›†å…¨å±€ç´¢å¼•ï¼Œåˆ’åˆ†åå­é›†ä¼šè‡ªåŠ¨æ˜ å°„ï¼‰
        row = self.data_frame.iloc[idx]
        filename = row['filename']
        encoded_label = row['encoded_label']

        # æ„å»ºå›¾åƒè·¯å¾„
        img_path = os.path.join(self.image_dir, filename)

        # åŠ è½½å›¾åƒï¼ˆå¤„ç†å¯èƒ½çš„æŸåæ–‡ä»¶ï¼‰
        try:
            image = Image.open(img_path).convert('RGB')
            if image.size == (0, 0):
                raise ValueError("å›¾åƒå°ºå¯¸ä¸º0ï¼Œå¯èƒ½æŸå")
        except Exception as e:
            print(f"âŒ åŠ è½½å›¾ç‰‡å¤±è´¥ï¼ˆæŸåï¼‰: {img_path}, é”™è¯¯: {e}")
            image = Image.new('RGB', (224, 224), color='black')

        # åº”ç”¨å½“å‰æ•°æ®é›†çš„é¢„å¤„ç†ï¼ˆè®­ç»ƒé›†å¸¦å¢å¼ºï¼ŒéªŒè¯é›†æ— å¢å¼ºï¼‰
        if self.transform:
            image = self.transform(image)

        return image, encoded_label

    def get_label_mapping(self):
        """è·å–åŸå§‹ç±»åˆ«IDåˆ°ç¼–ç æ ‡ç­¾çš„æ˜ å°„ï¼ˆå…¨å±€ç»Ÿä¸€ï¼‰"""
        return dict(zip(self.label_encoder.classes_, self.label_encoder.transform(self.label_encoder.classes_)))


# ---------------------- æ ¸å¿ƒä¿®æ”¹ï¼šåˆ†åˆ«å®šä¹‰è®­ç»ƒé›†/éªŒè¯é›†é¢„å¤„ç† ----------------------
# 1. è®­ç»ƒé›†é¢„å¤„ç†ï¼ˆå¸¦éšæœºå¢å¼ºï¼Œæå‡æ³›åŒ–èƒ½åŠ›ï¼‰
train_transform = transforms.Compose([
    transforms.Resize((256, 256)),
    transforms.RandomCrop(224),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.RandomVerticalFlip(p=0.2),
    # æ–°å¢å¢å¼º
    transforms.RandomRotation(degrees=15),  # éšæœºæ—‹è½¬Â±15åº¦
    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),  # é¢œè‰²æŠ–åŠ¨
    transforms.RandomGrayscale(p=0.1),  # 10%æ¦‚ç‡è½¬ä¸ºç°åº¦å›¾
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])
# 2. éªŒè¯é›†é¢„å¤„ç†ï¼ˆæ— éšæœºæ“ä½œï¼Œç¡®ä¿è¯„ä¼°ç»“æœç¨³å®šï¼‰
val_transform = transforms.Compose([
    transforms.Resize((256, 256)),
    transforms.CenterCrop(224),  # ä¸­å¿ƒè£å‰ªï¼ˆæ›¿ä»£éšæœºè£å‰ªï¼ŒéªŒè¯ä¸“ç”¨ï¼‰
    transforms.ToTensor(),  # æ— ç¿»è½¬æ“ä½œ
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ä¸è®­ç»ƒé›†å½’ä¸€åŒ–ä¸€è‡´
])


# ---------------------- æ ¸å¿ƒä¿®æ”¹ï¼šåˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›† ----------------------

# 1. åˆå§‹åŒ–å®Œæ•´æ•°æ®é›†ï¼ˆå…ˆè¿‡æ»¤æ— æ•ˆå›¾ç‰‡ï¼Œå†åˆ’åˆ†ï¼‰
full_dataset = PlantImageDataset(
    csv_file=r"F:\è®¡æŒ‘èµ›\train_labels.csv",
    image_dir=r"F:\è®¡æŒ‘èµ›\train",
    transform=None  # å…ˆä¸æŒ‡å®štransformï¼Œåˆ’åˆ†åå†åˆ†åˆ«èµ‹å€¼
)

# 2. å®šä¹‰åˆ’åˆ†æ¯”ä¾‹ï¼ˆéªŒè¯é›†å 10%ï¼Œå¯è°ƒæ•´ä¸º0.2å³20%ï¼‰
val_ratio = 0.1
val_size = int(val_ratio * len(full_dataset))
train_size = len(full_dataset) - val_size

# 3. éšæœºåˆ’åˆ†ï¼ˆè®¾ç½®seedä¿è¯æ¯æ¬¡åˆ’åˆ†ç»“æœä¸€è‡´ï¼‰
torch.manual_seed(42)  # å›ºå®šéšæœºç§å­ï¼Œå¤ç°æ€§å¼º
train_subset, val_subset = random_split(
    dataset=full_dataset,
    lengths=[train_size, val_size],
    generator=torch.Generator().manual_seed(42)  # è¿›ä¸€æ­¥ç¡®ä¿åˆ’åˆ†ç¨³å®š
)

# 4. ä¸ºå­é›†æŒ‡å®šä¸“å±é¢„å¤„ç†ï¼ˆå…³é”®ï¼šè®­ç»ƒé›†å¢å¼ºï¼ŒéªŒè¯é›†ä¸å¢å¼ºï¼‰
train_subset.dataset.transform = train_transform  # è®­ç»ƒå­é›†ç”¨è®­ç»ƒé¢„å¤„ç†
val_subset.dataset.transform = val_transform      # éªŒè¯å­é›†ç”¨éªŒè¯é¢„å¤„ç†

# 5. åˆ›å»ºè®­ç»ƒé›†/éªŒè¯é›†DataLoader
train_dataloader = DataLoader(
    train_subset,
    batch_size=32,
    shuffle=True,  # è®­ç»ƒé›†æ‰“ä¹±
    pin_memory=True,
    drop_last=True  # è®­ç»ƒé›†ä¸¢å¼ƒä¸å®Œæ•´æ‰¹æ¬¡
)

val_dataloader = DataLoader(
    val_subset,
    batch_size=32,
    shuffle=False,  # éªŒè¯é›†ä¸æ‰“ä¹±ï¼ˆè¯„ä¼°ç¨³å®šï¼‰
    pin_memory=True,
    drop_last=False  # éªŒè¯é›†ä¿ç•™ä¸å®Œæ•´æ‰¹æ¬¡ï¼ˆä¸æµªè´¹æ ·æœ¬ï¼‰
)

# 6. æ‰“å°åˆ’åˆ†ç»“æœ
print(f"\nâœ… æ•°æ®é›†åˆ’åˆ†å®Œæˆï¼š")
print(f"è®­ç»ƒé›†æ ·æœ¬æ•°: {len(train_subset)} | è®­ç»ƒé›†æ‰¹æ¬¡æ•°é‡: {len(train_dataloader)}")
print(f"éªŒè¯é›†æ ·æœ¬æ•°: {len(val_subset)} | éªŒè¯é›†æ‰¹æ¬¡æ•°é‡: {len(val_dataloader)}")

# 7. ï¼ˆå¯é€‰ï¼‰éªŒè¯å­é›†åŠ è½½æ•ˆæœ
def check_subset_loader(loader, name):
    print(f"\nğŸ” éªŒè¯{name}åŠ è½½å™¨ï¼š")
    for batch_idx, (images, labels) in enumerate(loader):
        print(f"æ‰¹æ¬¡ {batch_idx}: å›¾åƒå½¢çŠ¶ {images.shape}ï¼Œæ ‡ç­¾å½¢çŠ¶ {labels.shape}")
        print(f"æ ‡ç­¾èŒƒå›´: {labels.min().item()} - {labels.max().item()}")
        if batch_idx >= 1:  # ä»…éªŒè¯å‰2ä¸ªæ‰¹æ¬¡
            break

check_subset_loader(train_dataloader, "è®­ç»ƒé›†")
check_subset_loader(val_dataloader, "éªŒè¯é›†")

# è·å–å…¨å±€æ ‡ç­¾æ˜ å°„ï¼ˆåˆ’åˆ†åä»å…±ç”¨ï¼‰
label_mapping = full_dataset.get_label_mapping()
print(f"\næ€»ç±»åˆ«æ•°é‡: {len(label_mapping)}")


