#!/usr/bin/env python3
"""
èŠ±å‰åˆ†ç±» ViT-MoE æ¨¡å‹é¢„æµ‹è„šæœ¬

ä½¿ç”¨æ–¹æ³•:
    python ./code/predict.py <æµ‹è¯•é›†CSVè·¯å¾„> <æµ‹è¯•é›†å›¾ç‰‡ç›®å½•> <è¾“å‡ºæ–‡ä»¶è·¯å¾„>

ç¤ºä¾‹:
    python ./code/predict.py ./data/test_labels.csv ./data/test ./results/submission.csv

è¾“å‡ºæ ¼å¼:
    CSVæ–‡ä»¶åŒ…å«ä¸‰åˆ—: filename, category_id, confidence
    - filename: æµ‹è¯•å›¾ç‰‡æ–‡ä»¶åï¼ˆä¸æµ‹è¯•é›†CSVä¸€è‡´ï¼‰
    - category_id: é¢„æµ‹çš„èŠ±å‰ç±»åˆ«IDï¼ˆåŸå§‹ç±»åˆ«ç¼–å·ï¼‰
    - confidence: é¢„æµ‹ç½®ä¿¡åº¦ï¼ˆ0-1ä¹‹é—´ï¼Œä¿ç•™4ä½å°æ•°ï¼‰
"""

import os
import argparse
import pandas as pd
import torch
import tqdm
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from PIL import Image
import joblib


# ---------------------- 1. æµ‹è¯•é›†æ•°æ®é›†ç±»ï¼ˆä¿ç•™åŸæœ‰æ ¸å¿ƒé€»è¾‘ï¼‰ ----------------------
class TestPlantImageDataset(Dataset):
    def __init__(self, test_csv_path, test_image_dir, transform=None):
        self.test_image_dir = test_image_dir
        self.transform = transform

        # è¯»å–æµ‹è¯•é›†CSVï¼ˆæ”¯æŒå¤šç¼–ç ï¼‰
        try:
            self.test_df = pd.read_csv(test_csv_path, encoding='utf-8')
        except UnicodeDecodeError:
            self.test_df = pd.read_csv(test_csv_path, encoding='gbk')

        # æ ¡éªŒCSVæ ¼å¼ï¼ˆå¿…é¡»åŒ…å«"image_name"åˆ—ï¼‰
        assert "image_name" in self.test_df.columns, "æµ‹è¯•é›†CSVå¿…é¡»åŒ…å«'image_name'åˆ—"
        self.image_names = self.test_df["image_name"].tolist()  # ä»CSVè·å–å›¾ç‰‡å

    def __len__(self):
        return len(self.image_names)

    def __getitem__(self, idx):
        image_name = self.image_names[idx]
        image_path = os.path.join(self.test_image_dir, image_name)

        # åŠ è½½å›¾ç‰‡ï¼ˆå¤„ç†æŸå/å¼‚å¸¸æ–‡ä»¶ï¼‰
        try:
            image = Image.open(image_path).convert('RGB')
            if image.size == (0, 0):
                raise ValueError("å›¾ç‰‡å°ºå¯¸ä¸ºç©º")
        except Exception as e:
            print(f"âš ï¸ åŠ è½½å›¾ç‰‡å¤±è´¥: {image_path} | é”™è¯¯: {e} | ç”¨é»‘è‰²å›¾æ›¿ä»£")
            image = Image.new('RGB', (600, 600), color='black')  # èµ›é¢˜å›¾ç‰‡é»˜è®¤600Ã—600

        # åº”ç”¨é¢„å¤„ç†ï¼ˆæ— éšæœºæ“ä½œï¼Œä¿è¯æ¨ç†ä¸€è‡´ï¼‰
        if self.transform:
            image = self.transform(image)

        return image, image_name  # è¿”å›ï¼šå¤„ç†åå›¾ç‰‡ + åŸå§‹æ–‡ä»¶å


# ---------------------- 2. æ ¸å¿ƒé¢„æµ‹å‡½æ•°ï¼ˆä¿ç•™çœŸå®æ¨¡å‹æ¨ç†é€»è¾‘ï¼‰ ----------------------
def model_predict(model, test_loader, device, model_path, label_encoder_path, output_csv_path):
    """
    ç”¨è®­ç»ƒå¥½çš„ViT-MoEæ¨¡å‹é¢„æµ‹æµ‹è¯•é›†ï¼Œç”Ÿæˆæ ‡å‡†CSVç»“æœ
    """
    # åŠ è½½æœ€ä¼˜æ¨¡å‹æƒé‡
    if not os.path.exists(model_path):
        raise FileNotFoundError(f"æ¨¡å‹æƒé‡æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
    checkpoint = torch.load(model_path, map_location=device)
    model.load_state_dict(checkpoint['model_state_dict'])
    print(f"âœ… åŠ è½½æ¨¡å‹æˆåŠŸ | è®­ç»ƒæœ€ä½³éªŒè¯å‡†ç¡®ç‡: {checkpoint.get('best_val_acc', 0):.2f}% | è®­ç»ƒè½®æ¬¡: {checkpoint.get('epoch', 0)}")

    # åŠ è½½LabelEncoderï¼ˆç¼–ç æ ‡ç­¾â†’åŸå§‹ç±»åˆ«IDï¼‰
    if not os.path.exists(label_encoder_path):
        raise FileNotFoundError(f"LabelEncoderæ–‡ä»¶ä¸å­˜åœ¨: {label_encoder_path}")
    label_encoder = joblib.load(label_encoder_path)
    print(f"âœ… åŠ è½½LabelEncoderæˆåŠŸ | ç±»åˆ«æ€»æ•°: {len(label_encoder.classes_)}")

    # æ¨¡å‹åˆ‡æ¢ä¸ºè¯„ä¼°æ¨¡å¼ï¼ˆå…³é—­Dropout/MoEéšæœºé€‰æ‹©ï¼‰
    model.eval()
    predictions = []  # å­˜å‚¨ç»“æœï¼š(filename, category_id, confidence)

    # æ— æ¢¯åº¦æ¨ç†ï¼ˆèŠ‚çœæ˜¾å­˜+åŠ é€Ÿï¼‰
    with torch.no_grad():
        predict_loop = tqdm.tqdm(
            enumerate(test_loader),
            total=len(test_loader),
            desc="ğŸ” æµ‹è¯•é›†é¢„æµ‹ä¸­",
            leave=True
        )

        for batch_idx, (images, image_names) in predict_loop:
            images = images.to(device)

            # æ¨¡å‹å‰å‘ä¼ æ’­ï¼ˆè¾“å‡ºlogitsï¼‰
            outputs = model(images)  # shape: (batch_size, num_classes)
            # è®¡ç®—ç½®ä¿¡åº¦ï¼ˆsoftmaxå½’ä¸€åŒ–â†’æ¦‚ç‡åˆ†å¸ƒï¼‰
            probs = torch.softmax(outputs, dim=1)
            # è·å–æ¯ä¸ªæ ·æœ¬çš„æœ€å¤§ç½®ä¿¡åº¦åŠå¯¹åº”ç±»åˆ«ç´¢å¼•
            max_probs, encoded_preds = torch.max(probs, dim=1)

            # ç¼–ç æ ‡ç­¾â†’åŸå§‹ç±»åˆ«IDï¼ˆä¸èµ›é¢˜ç±»åˆ«IDä¸€è‡´ï¼‰
            raw_category_ids = label_encoder.inverse_transform(encoded_preds.cpu().numpy())
            # ç½®ä¿¡åº¦è½¬ä¸ºPythonæ•°å€¼ï¼ˆä¿ç•™4ä½å°æ•°ï¼‰
            confidences = [round(prob.item(), 4) for prob in max_probs]

            # æ”¶é›†å½“å‰æ‰¹æ¬¡ç»“æœ
            batch_results = list(zip(image_names, raw_category_ids, confidences))
            predictions.extend(batch_results)

    # ç”Ÿæˆæ ‡å‡†CSVï¼ˆåˆ—åä¸å‚è€ƒè„šæœ¬ä¸€è‡´ï¼šfilename, category_id, confidenceï¼‰
    pred_df = pd.DataFrame(
        predictions,
        columns=["filename", "category_id", "confidence"]
    )
    # æŒ‰æ–‡ä»¶åæ’åºï¼ˆä¿è¯ä¸æµ‹è¯•é›†é¡ºåºä¸€è‡´ï¼‰
    pred_df = pred_df.sort_values("filename").reset_index(drop=True)

    # ä¿å­˜CSVï¼ˆUTF-8ç¼–ç ï¼Œé¿å…æœåŠ¡å™¨è§£æä¹±ç ï¼‰
    output_dir = os.path.dirname(output_csv_path)
    if output_dir and not os.path.exists(output_dir):
        os.makedirs(output_dir, exist_ok=True)
        print(f"ğŸ“ åˆ›å»ºè¾“å‡ºç›®å½•: {output_dir}")
    pred_df.to_csv(output_csv_path, index=False, encoding='utf-8')

    # æ‰“å°é¢„æµ‹æ€»ç»“
    print(f"\nğŸ‰ é¢„æµ‹å®Œæˆï¼")
    print(f"ğŸ“Š é¢„æµ‹æ ·æœ¬æ€»æ•°: {len(pred_df)}")
    print(f"ğŸ’¾ ç»“æœä¿å­˜è·¯å¾„: {output_csv_path}")
    print(f"ğŸ“„ CSVæ ¼å¼ç¤ºä¾‹:\n{pred_df.head(3)}")

    return pred_df


# ---------------------- 3. ä¸»å‡½æ•°ï¼ˆå¯¹é½å‚è€ƒè„šæœ¬çš„å‘½ä»¤è¡Œå‚æ•°é£æ ¼ï¼‰ ----------------------
def main():
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description='èŠ±å‰åˆ†ç±» ViT-MoE æ¨¡å‹é¢„æµ‹è„šæœ¬')

    # ä½ç½®å‚æ•°ï¼ˆå¿…é¡»ä¼ å…¥ï¼Œé¡ºåºå›ºå®šï¼‰
    parser.add_argument('test_csv_path', type=str,
                        help='æµ‹è¯•é›†CSVæ–‡ä»¶è·¯å¾„ï¼ˆéœ€åŒ…å«"image_name"åˆ—ï¼‰')
    parser.add_argument('test_img_dir', type=str,
                        help='æµ‹è¯•é›†å›¾ç‰‡å­˜æ”¾ç›®å½•')
    parser.add_argument('output_path', type=str,
                        help='é¢„æµ‹ç»“æœè¾“å‡ºCSVè·¯å¾„ï¼ˆå¦‚./results/submission.csvï¼‰')

    # å¯é€‰å‚æ•°ï¼ˆé»˜è®¤å€¼å¯¹é½ä½ çš„åŸæœ‰é…ç½®ï¼‰
    parser.add_argument('--model_path', type=str, default='./models/best_model.pth',
                        help='è®­ç»ƒå¥½çš„æ¨¡å‹æƒé‡è·¯å¾„ï¼ˆé»˜è®¤: ./models/best_model.pthï¼‰')
    parser.add_argument('--label_encoder_path', type=str, default='./models/label_encoder.pkl',
                        help='LabelEncoderæ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤: ./models/label_encoder.pklï¼‰')
    parser.add_argument('--batch_size', type=int, default=32,
                        help='æ¨ç†æ‰¹æ¬¡å¤§å°ï¼ˆé»˜è®¤: 32ï¼Œæ ¹æ®æ˜¾å­˜è°ƒæ•´ï¼‰')
    parser.add_argument('--img_size', type=int, default=224,
                        help='æ¨¡å‹è¾“å…¥å›¾åƒå°ºå¯¸ï¼ˆé»˜è®¤: 224ï¼Œéœ€ä¸è®­ç»ƒä¸€è‡´ï¼‰')
    parser.add_argument('--device', type=str, default=None,
                        help='æŒ‡å®šè¿è¡Œè®¾å¤‡ï¼ˆcuda/cpuï¼Œé»˜è®¤è‡ªåŠ¨æ£€æµ‹ï¼‰')
    parser.add_argument('--seed', type=int, default=42,
                        help='éšæœºç§å­ï¼ˆä¿è¯æŸåå›¾ç‰‡å¤„ç†ä¸€è‡´æ€§ï¼Œé»˜è®¤: 42ï¼‰')

    args = parser.parse_args()

    # åŸºç¡€é…ç½®åˆå§‹åŒ–
    torch.manual_seed(args.seed)  # å›ºå®šç§å­ï¼Œç¡®ä¿å¯å¤ç°
    # è‡ªåŠ¨æ£€æµ‹è®¾å¤‡ï¼ˆä¼˜å…ˆcudaï¼‰
    if args.device is None:
        args.device = 'cuda' if torch.cuda.is_available() else 'cpu'
    device = torch.device(args.device)

    # æ‰“å°å‚æ•°ä¿¡æ¯ï¼ˆå¯¹é½å‚è€ƒè„šæœ¬çš„æ—¥å¿—é£æ ¼ï¼‰
    print("=" * 60)
    print("ğŸ“‹ é¢„æµ‹å‚æ•°é…ç½®")
    print("=" * 60)
    print(f"æµ‹è¯•é›†CSVè·¯å¾„: {args.test_csv_path}")
    print(f"æµ‹è¯•é›†å›¾ç‰‡ç›®å½•: {args.test_img_dir}")
    print(f"ç»“æœè¾“å‡ºè·¯å¾„: {args.output_path}")
    print(f"æ¨¡å‹æƒé‡è·¯å¾„: {args.model_path}")
    print(f"LabelEncoderè·¯å¾„: {args.label_encoder_path}")
    print(f"æ‰¹æ¬¡å¤§å°: {args.batch_size} | è¾“å…¥å°ºå¯¸: {args.img_size} | è®¾å¤‡: {args.device} | ç§å­: {args.seed}")
    print("=" * 60)

    # æ£€æŸ¥å¿…è¦è·¯å¾„æ˜¯å¦å­˜åœ¨
    if not os.path.exists(args.test_csv_path):
        print(f"âŒ é”™è¯¯: æµ‹è¯•é›†CSVä¸å­˜åœ¨: {args.test_csv_path}")
        return
    if not os.path.exists(args.test_img_dir):
        print(f"âŒ é”™è¯¯: æµ‹è¯•é›†å›¾ç‰‡ç›®å½•ä¸å­˜åœ¨: {args.test_img_dir}")
        return

    # 1. åˆå§‹åŒ–æµ‹è¯•é›†é¢„å¤„ç†ï¼ˆä¸è®­ç»ƒä¸€è‡´ï¼Œæ— éšæœºå¢å¼ºï¼‰
    test_transform = transforms.Compose([
        transforms.Resize((256, 256)),  # å…ˆç¼©æ”¾è‡³256Ã—256
        transforms.CenterCrop(args.img_size),  # ä¸­å¿ƒè£å‰ªè‡³è¾“å…¥å°ºå¯¸
        transforms.ToTensor(),
        transforms.Normalize(  # ImageNetå‡å€¼/æ ‡å‡†å·®ï¼ˆä¸è®­ç»ƒä¸€è‡´ï¼‰
            mean=[0.485, 0.456, 0.406],
            std=[0.229, 0.224, 0.225]
        )
    ])

    # 2. åˆå§‹åŒ–æµ‹è¯•é›†åŠ è½½å™¨
    test_dataset = TestPlantImageDataset(
        test_csv_path=args.test_csv_path,
        test_image_dir=args.test_img_dir,
        transform=test_transform
    )
    test_loader = DataLoader(
        test_dataset,
        batch_size=args.batch_size,
        shuffle=False,  # æµ‹è¯•é›†ä¸æ‰“ä¹±ï¼Œä¿è¯é¡ºåºä¸€è‡´
        pin_memory=True,  # åŠ é€Ÿæ•°æ®ä¼ è¾“åˆ°GPU
        num_workers=2  # Windowså»ºè®®â‰¤2ï¼Œé¿å…çº¿ç¨‹æŠ¥é”™
    )
    print(f"âœ… æµ‹è¯•é›†åŠ è½½å®Œæˆ | å›¾ç‰‡æ€»æ•°: {len(test_dataset)} | æ‰¹æ¬¡æ€»æ•°: {len(test_loader)}")

    # 3. åˆå§‹åŒ–ViT-MoEæ¨¡å‹ï¼ˆå‚æ•°ä¸è®­ç»ƒä¸€è‡´ï¼‰
    from code.model import vit_base_patch16_224_moe  # å¯¼å…¥ä½ çš„æ¨¡å‹
    model = vit_base_patch16_224_moe(
        num_experts=2,
        top_k=1,
        classes=100,  # èµ›é¢˜100ç±»èŠ±å‰
        img_size=args.img_size,
        patch_size=16,
        in_channel=3,
        embed_dim=256,
        depth=2,
        num_heads=4,
        mlp_ratio=2.0
    ).to(device)
    print(f"âœ… ViT-MoEæ¨¡å‹åˆå§‹åŒ–å®Œæˆ | è®¾å¤‡: {args.device}")

    # 4. å¯åŠ¨æ¨¡å‹é¢„æµ‹
    model_predict(
        model=model,
        test_loader=test_loader,
        device=device,
        model_path=args.model_path,
        label_encoder_path=args.label_encoder_path,
        output_csv_path=args.output_path
    )


if __name__ == '__main__':
    main()