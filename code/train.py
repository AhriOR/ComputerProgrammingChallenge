#!/usr/bin/env python3
"""
èŠ±å‰åˆ†ç±» ViT-MoE æ¨¡å‹è®­ç»ƒè„šæœ¬
"""

import os
import time
import json
import argparse
from pathlib import Path

import torch
import torch.nn as nn
import torch.optim as optim
from torch.optim.lr_scheduler import LambdaLR, CosineAnnealingLR, SequentialLR
import tqdm

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—ï¼ˆä¿æŒä½ çš„åŸæœ‰æ•°æ®å’Œæ¨¡å‹é€»è¾‘ï¼‰
from code.utils import train_dataloader, val_dataloader
from model import vit_base_patch16_224_moe


# ---------------------- è¾…åŠ©ç±»ä¸å‡½æ•°ï¼ˆå‚è€ƒç¤ºä¾‹é£æ ¼ï¼Œè§„èŒƒåŒ–ç»Ÿè®¡ï¼‰ ----------------------
class AverageMeter:
    """ç”¨äºç»Ÿè®¡å¹³å‡æŸå¤±å’Œå‡†ç¡®ç‡çš„å·¥å…·ç±»"""
    def __init__(self):
        self.reset()

    def reset(self):
        self.val = 0  # å½“å‰æ‰¹æ¬¡å€¼
        self.avg = 0  # å¹³å‡å€¼
        self.sum = 0  # æ€»å’Œ
        self.count = 0  # æ ·æœ¬æ•°

    def update(self, val, n=1):
        self.val = val
        self.sum += val * n
        self.count += n
        self.avg = self.sum / self.count


def calculate_accuracy(outputs, labels, topk=(1,)):
    """è®¡ç®—Top-kå‡†ç¡®ç‡ï¼ˆå‚è€ƒç¤ºä¾‹ï¼Œæ”¯æŒTop1/Top5ï¼‰"""
    with torch.no_grad():
        maxk = max(topk)
        batch_size = labels.size(0)

        # è·å–å‰maxkä¸ªé¢„æµ‹ç»“æœçš„ç´¢å¼•
        _, pred = outputs.topk(maxk, 1, True, True)
        pred = pred.t()  # è½¬ç½®ä¸º (k, batch_size)
        correct = pred.eq(labels.view(1, -1).expand_as(pred))  # ä¸çœŸå®æ ‡ç­¾å¯¹æ¯”

        res = []
        for k in topk:
            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)
            res.append(correct_k.mul_(100.0 / batch_size))  # è½¬ä¸ºç™¾åˆ†æ¯”
        return res


def save_config(config, save_path):
    """ä¿å­˜è®­ç»ƒé…ç½®åˆ°JSONæ–‡ä»¶ï¼ˆå‚è€ƒç¤ºä¾‹çš„é…ç½®ä¿å­˜é€»è¾‘ï¼‰"""
    with open(save_path, 'w', encoding='utf-8') as f:
        json.dump(config, f, ensure_ascii=False, indent=4)
    print(f"âœ… è®­ç»ƒé…ç½®å·²ä¿å­˜è‡³: {save_path}")


def set_seed(seed=42):
    """è®¾ç½®éšæœºç§å­ï¼Œä¿è¯å®éªŒå¯å¤ç°ï¼ˆå‚è€ƒç¤ºä¾‹ï¼‰"""
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False


# ---------------------- æ ¸å¿ƒè®­ç»ƒ/éªŒè¯å‡½æ•°ï¼ˆæ‹†åˆ†é€»è¾‘ï¼Œå‚è€ƒç¤ºä¾‹ç»“æ„ï¼‰ ----------------------
def train_epoch(model, train_loader, criterion, optimizer, device, epoch):
    """å•è½®è®­ç»ƒå‡½æ•°ï¼ˆè§„èŒƒåŒ–ç»Ÿè®¡ä¸æ—¥å¿—è¾“å‡ºï¼‰"""
    model.train()
    losses = AverageMeter()
    top1 = AverageMeter()  # Top1å‡†ç¡®ç‡

    train_loop = tqdm.tqdm(
        enumerate(train_loader),
        total=len(train_loader),
        desc=f"Epoch [{epoch+1}]/Train",
        leave=False
    )

    for batch_idx, (images, labels) in train_loop:
        images, labels = images.to(device), labels.to(device)

        # å‰å‘ä¼ æ’­
        outputs = model(images)
        loss = criterion(outputs, labels)

        # åå‘ä¼ æ’­ä¸å‚æ•°æ›´æ–°
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        # ç»Ÿè®¡æŒ‡æ ‡
        acc1 = calculate_accuracy(outputs, labels, topk=(1,))[0]
        losses.update(loss.item(), images.size(0))
        top1.update(acc1.item(), images.size(0))

        # æ›´æ–°è¿›åº¦æ¡
        train_loop.set_postfix({
            "batch_loss": f"{loss.item():.4f}",
            "avg_loss": f"{losses.avg:.4f}",
            "avg_acc1": f"{top1.avg:.2f}%"
        })

    # æ‰“å°å•è½®è®­ç»ƒæ€»ç»“
    print(f"Epoch [{epoch+1}]/Train | Loss: {losses.avg:.4f} | Acc@1: {top1.avg:.2f}%")
    return losses.avg, top1.avg


def validate_epoch(model, val_loader, criterion, device):
    """å•è½®éªŒè¯å‡½æ•°ï¼ˆæ— æ¢¯åº¦è®¡ç®—ï¼Œè§„èŒƒåŒ–ç»Ÿè®¡ï¼‰"""
    model.eval()
    losses = AverageMeter()
    top1 = AverageMeter()

    with torch.no_grad():  # å…³é—­æ¢¯åº¦ï¼ŒèŠ‚çœæ˜¾å­˜
        val_loop = tqdm.tqdm(
            enumerate(val_loader),
            total=len(val_loader),
            desc="Validating",
            leave=False
        )

        for batch_idx, (images, labels) in val_loop:
            images, labels = images.to(device), labels.to(device)

            # å‰å‘ä¼ æ’­
            outputs = model(images)
            loss = criterion(outputs, labels)

            # ç»Ÿè®¡æŒ‡æ ‡
            acc1 = calculate_accuracy(outputs, labels, topk=(1,))[0]
            losses.update(loss.item(), images.size(0))
            top1.update(acc1.item(), images.size(0))

            # æ›´æ–°è¿›åº¦æ¡
            val_loop.set_postfix({
                "batch_loss": f"{loss.item():.4f}",
                "avg_loss": f"{losses.avg:.4f}",
                "avg_acc1": f"{top1.avg:.2f}%"
            })

    # æ‰“å°å•è½®éªŒè¯æ€»ç»“
    print(f"Validation | Loss: {losses.avg:.4f} | Acc@1: {top1.avg:.2f}%")
    return losses.avg, top1.avg


# ---------------------- ä¸»å‡½æ•°ï¼ˆå‘½ä»¤è¡Œå‚æ•°ã€è®­ç»ƒæµç¨‹æ§åˆ¶ï¼Œå‚è€ƒç¤ºä¾‹æ ¸å¿ƒç»“æ„ï¼‰ ----------------------
def main():
    # 1. è§£æå‘½ä»¤è¡Œå‚æ•°ï¼ˆå‚è€ƒç¤ºä¾‹ï¼Œæ”¯æŒçµæ´»é…ç½®ï¼‰
    parser = argparse.ArgumentParser(description='èŠ±å‰åˆ†ç±» ViT-MoE æ¨¡å‹è®­ç»ƒ')
    # æ¨¡å‹å‚æ•°
    parser.add_argument('--model_type', type=str, default='vit_moe', help='æ¨¡å‹ç±»å‹ï¼ˆå›ºå®šä¸ºViT-MoEï¼‰')
    parser.add_argument('--num_classes', type=int, default=100, help='ç±»åˆ«æ•°é‡')
    parser.add_argument('--num_experts', type=int, default=4, help='MoEä¸“å®¶æ•°é‡')
    parser.add_argument('--top_k', type=int, default=2, help='MoEæ¯æ ·æœ¬é€‰æ‹©ä¸“å®¶æ•°')
    parser.add_argument('--embed_dim', type=int, default=512, help='ViTåµŒå…¥ç»´åº¦')
    parser.add_argument('--depth', type=int, default=6, help='ViT Transformerå—æ•°é‡')
    parser.add_argument('--num_heads', type=int, default=8, help='å¤šå¤´æ³¨æ„åŠ›å¤´æ•°')
    parser.add_argument('--mlp_ratio', type=float, default=2.0, help='MLPéšè—å±‚æ¯”ä¾‹')
    parser.add_argument('--img_size', type=int, default=224, help='è¾“å…¥å›¾åƒå°ºå¯¸')
    parser.add_argument('--patch_size', type=int, default=16, help='Patchåˆ†å—å°ºå¯¸')
    # è®­ç»ƒå‚æ•°
    parser.add_argument('--batch_size', type=int, default=32, help='æ‰¹æ¬¡å¤§å°')
    parser.add_argument('--epochs', type=int, default=50, help='è®­ç»ƒè½®æ•°')
    parser.add_argument('--lr', type=float, default=5e-4, help='åˆå§‹å­¦ä¹ ç‡')
    parser.add_argument('--weight_decay', type=float, default=1e-4, help='æƒé‡è¡°å‡')
    parser.add_argument('--warmup_epochs', type=int, default=5, help='Warmupè½®æ•°')
    parser.add_argument('--eta_min', type=float, default=1e-6, help='ä½™å¼¦é€€ç«æœ€å°å­¦ä¹ ç‡')
    # è·¯å¾„ä¸è®¾å¤‡å‚æ•°
    parser.add_argument('--save_dir', type=str, default='../models', help='æ¨¡å‹ä¿å­˜ç›®å½•')
    parser.add_argument('--resume', type=str, default=None, help='æ¢å¤è®­ç»ƒçš„Checkpointè·¯å¾„')
    parser.add_argument('--device', type=str, default=None, help='æŒ‡å®šè®¾å¤‡ï¼ˆcuda/cpuï¼Œé»˜è®¤è‡ªåŠ¨æ£€æµ‹ï¼‰')
    parser.add_argument('--seed', type=int, default=42, help='éšæœºç§å­')

    args = parser.parse_args()

    # 2. åŸºç¡€é…ç½®åˆå§‹åŒ–
    set_seed(args.seed)  # å›ºå®šç§å­
    # è‡ªåŠ¨æ£€æµ‹è®¾å¤‡ï¼ˆä¼˜å…ˆcudaï¼‰
    if args.device is None:
        args.device = 'cuda' if torch.cuda.is_available() else 'cpu'
    device = torch.device(args.device)
    print(f"ğŸ“Œ ä½¿ç”¨è®¾å¤‡: {device}")

    # åˆ›å»ºä¿å­˜ç›®å½•
    os.makedirs(args.save_dir, exist_ok=True)
    print(f"ğŸ“Œ æ¨¡å‹ä¿å­˜ç›®å½•: {args.save_dir}")

    # 3. æ•°æ®åŠ è½½ï¼ˆä¿ç•™ä½ çš„åŸæœ‰é€»è¾‘ï¼Œä»code.utilså¯¼å…¥ï¼‰
    print("\nğŸ” åŠ è½½æ•°æ®åŠ è½½å™¨...")
    train_loader = train_dataloader
    val_loader = val_dataloader
    # è·å–ç±»åˆ«æ˜ å°„ï¼ˆä»æ•°æ®é›†çš„LabelEncoderè·å–ï¼‰
    # æ³¨ï¼štrain_loader.dataset æ˜¯Subsetï¼Œå…¶datasetæ˜¯PlantImageDatasetå®ä¾‹
    label_encoder = train_loader.dataset.dataset.label_encoder
    class_to_idx = dict(zip(label_encoder.classes_, range(len(label_encoder.classes_))))
    print(f"âœ… æ•°æ®åŠ è½½å®Œæˆ | è®­ç»ƒé›†æ ·æœ¬: {len(train_loader.dataset)} | éªŒè¯é›†æ ·æœ¬: {len(val_loader.dataset)} | ç±»åˆ«æ•°: {len(class_to_idx)}")

    # 4. æ¨¡å‹åˆå§‹åŒ–ï¼ˆä¿ç•™ä½ çš„ViT-MoEå®ä¾‹åŒ–é€»è¾‘ï¼‰
    print("\nğŸ”§ åˆ›å»º ViT-MoE æ¨¡å‹...")
    model = vit_base_patch16_224_moe(
        num_experts=args.num_experts,
        top_k=args.top_k,
        classes=args.num_classes,
        img_size=args.img_size,
        patch_size=args.patch_size,
        in_channel=3,
        embed_dim=args.embed_dim,
        depth=args.depth,
        num_heads=args.num_heads,
        mlp_ratio=args.mlp_ratio
    ).to(device)
    print(f"âœ… æ¨¡å‹åˆ›å»ºå®Œæˆ | æ¨¡å‹å‚æ•°æ€»é‡: {sum(p.numel() for p in model.parameters() if p.requires_grad) / 1e6:.2f}M")

    # 5. ä¼˜åŒ–å™¨ä¸å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼ˆä¿ç•™ä½ çš„Warmup+ä½™å¼¦é€€ç«é€»è¾‘ï¼‰
    print("\nğŸ”§ åˆå§‹åŒ–ä¼˜åŒ–å™¨ä¸å­¦ä¹ ç‡è°ƒåº¦å™¨...")
    optimizer = optim.AdamW(
        model.parameters(),
        lr=args.lr,
        weight_decay=args.weight_decay,
        betas=(0.9, 0.999),
        eps=1e-08
    )
    # Warmupè°ƒåº¦å™¨
    warmup_scheduler = LambdaLR(optimizer, lr_lambda=lambda e: (e + 1) / args.warmup_epochs)
    # ä½™å¼¦é€€ç«è°ƒåº¦å™¨ï¼ˆæ€»è½®æ•°=æ€»epoch - warmupè½®æ•°ï¼‰
    main_epochs = args.epochs - args.warmup_epochs
    main_scheduler = CosineAnnealingLR(optimizer, T_max=main_epochs, eta_min=args.eta_min)
    # ç»„åˆè°ƒåº¦å™¨
    lr_scheduler = SequentialLR(optimizer, [warmup_scheduler, main_scheduler], [args.warmup_epochs])
    print(f"âœ… ä¼˜åŒ–å™¨: AdamW | åˆå§‹LR: {args.lr} | Warmupè½®æ•°: {args.warmup_epochs} | è°ƒåº¦å™¨: Warmup+CosineAnnealing")

    # 6. æŸå¤±å‡½æ•°
    criterion = nn.CrossEntropyLoss().to(device)

    # 7. æ¢å¤è®­ç»ƒï¼ˆå‚è€ƒç¤ºä¾‹çš„CheckpointåŠ è½½é€»è¾‘ï¼‰
    start_epoch = 0
    best_val_acc = 0.0
    # è®­ç»ƒå†å²è®°å½•ï¼ˆç”¨äºåç»­åˆ†æï¼‰
    history = {
        'train_loss': [],
        'train_acc1': [],
        'val_loss': [],
        'val_acc1': []
    }

    if args.resume is not None and os.path.exists(args.resume):
        print(f"\nğŸ”„ ä»Checkpointæ¢å¤è®­ç»ƒ: {args.resume}")
        checkpoint = torch.load(args.resume, map_location=device)
        # åŠ è½½å‚æ•°
        start_epoch = checkpoint['epoch']
        best_val_acc = checkpoint['best_val_acc']
        model.load_state_dict(checkpoint['model_state_dict'])
        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        lr_scheduler.load_state_dict(checkpoint['lr_scheduler_state_dict'])
        history = checkpoint.get('history', history)
        print(f"âœ… æ¢å¤å®Œæˆ | èµ·å§‹Epoch: {start_epoch} | å†å²æœ€ä½³Val Acc: {best_val_acc:.2f}%")
    elif args.resume is not None:
        print(f"âš ï¸ æœªæ‰¾åˆ°Checkpoint: {args.resume}ï¼Œå°†ä»å¤´å¼€å§‹è®­ç»ƒ")

    # 8. æ ¸å¿ƒè®­ç»ƒå¾ªç¯ï¼ˆå‚è€ƒç¤ºä¾‹çš„æµç¨‹ï¼Œæ•´åˆè®­ç»ƒ/éªŒè¯/ä¿å­˜ï¼‰
    print("\nğŸš€ å¼€å§‹è®­ç»ƒ...")
    for epoch in range(start_epoch, args.epochs):
        epoch_start_time = time.time()

        # 8.1 å•è½®è®­ç»ƒ
        train_loss, train_acc1 = train_epoch(model, train_loader, criterion, optimizer, device, epoch)
        # 8.2 å•è½®éªŒè¯
        val_loss, val_acc1 = validate_epoch(model, val_loader, criterion, device)
        # 8.3 æ›´æ–°å­¦ä¹ ç‡è°ƒåº¦å™¨
        lr_scheduler.step()
        # 8.4 è®°å½•è®­ç»ƒå†å²
        history['train_loss'].append(train_loss)
        history['train_acc1'].append(train_acc1)
        history['val_loss'].append(val_loss)
        history['val_acc1'].append(val_acc1)

        # 8.5 è®¡ç®—epochè€—æ—¶
        epoch_time = time.time() - epoch_start_time
        print(f"â±ï¸ Epoch [{epoch+1}] è€—æ—¶: {epoch_time:.1f}s | å½“å‰LR: {optimizer.param_groups[0]['lr']:.6f}\n")

        # 8.6 ä¿å­˜Checkpointï¼ˆå‚è€ƒç¤ºä¾‹çš„åŒCheckpointç­–ç•¥ï¼šlatest + bestï¼‰
        # ä¿å­˜æœ€æ–°Checkpointï¼ˆæ¯æ¬¡epochéƒ½ä¿å­˜ï¼‰
        latest_ckpt_path = os.path.join(args.save_dir, 'latest_checkpoint.pth')
        torch.save({
            'epoch': epoch + 1,
            'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'lr_scheduler_state_dict': lr_scheduler.state_dict(),
            'best_val_acc': best_val_acc,
            'history': history,
            'args': vars(args)  # ä¿å­˜å‘½ä»¤è¡Œå‚æ•°
        }, latest_ckpt_path)

        # ä¿å­˜æœ€ä½³Checkpointï¼ˆä»…å½“éªŒè¯å‡†ç¡®ç‡æå‡æ—¶ï¼‰
        is_best = val_acc1 > best_val_acc
        if is_best:
            best_val_acc = val_acc1
            best_ckpt_path = os.path.join(args.save_dir, 'best_model.pth')
            torch.save({
                'epoch': epoch + 1,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'lr_scheduler_state_dict': lr_scheduler.state_dict(),
                'best_val_acc': best_val_acc,
                'history': history,
                'args': vars(args)
            }, best_ckpt_path)
            print(f"ğŸŒŸ æœ€ä½³æ¨¡å‹å·²æ›´æ–° | æ–°æœ€ä½³Val Acc: {best_val_acc:.2f}% | ä¿å­˜è·¯å¾„: {best_ckpt_path}\n")

    # 9. è®­ç»ƒå®Œæˆåï¼šä¿å­˜é…ç½®ä¸å†å²è®°å½•ï¼ˆå‚è€ƒç¤ºä¾‹çš„æ”¶å°¾é€»è¾‘ï¼‰
    print("\nğŸ è®­ç»ƒå…¨éƒ¨å®Œæˆï¼")
    print(f"ğŸ“Š æœ€ç»ˆæœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_val_acc:.2f}%")

    # ä¿å­˜è®­ç»ƒé…ç½®
    config = {
        'model_config': {
            'model_type': args.model_type,
            'num_classes': args.num_classes,
            'num_experts': args.num_experts,
            'embed_dim': args.embed_dim,
            'img_size': args.img_size
        },
        'training_params': vars(args),
        'class_to_idx': class_to_idx,
        'best_val_acc': best_val_acc,
        'training_history': history
    }
    save_config(config, os.path.join(args.save_dir, 'train_config.json'))

    # ä¿å­˜è®­ç»ƒå†å²ï¼ˆå¯é€‰ï¼Œæ–¹ä¾¿åç»­åˆ†æï¼‰
    with open(os.path.join(args.save_dir, 'training_history.json'), 'w', encoding='utf-8') as f:
        json.dump(history, f, ensure_ascii=False, indent=4)
    print(f"âœ… è®­ç»ƒå†å²å·²ä¿å­˜è‡³: {os.path.join(args.save_dir, 'training_history.json')}")


if __name__ == "__main__":
    main()